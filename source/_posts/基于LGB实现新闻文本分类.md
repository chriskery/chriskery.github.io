---
title: 基于LGB实现新闻文本分类
date: 2024-05-01 20:05:08
tags:
---
## 0.概述
-   **任务描述**： 

识别样本中的敏感数据，构建基于敏感数据本体的分级分类模型，判断数据所属的类别以及级别。 1.利用远程监督技术，基于小样本构建文档分类分级样本库。 2.结合当下先进的深度学习和机器学习技术，利用已构建的样本库，提取文本语义特征，构建泛化能力强且能自我学习的文档分类分级模型。：
    

-   **数据集**： 

（1）已标注数据：共7000篇文档，类别包含7类，分别为：财经、房产、家居、教育、科技、时尚、时政，每一类包含1000篇文档。 （2）未标注数据：共33000篇文档。 （3）分类分级测试数据：共20000篇文档，包含10个类别:财经、房产、家居、教育、科技、时尚、时政、游戏、娱乐、体育。
    
-   **运行环境**：

Python3.7环境下测试了本教程代码。需要的第三方模块包括：
    
    ```
    operator
    numpy
    pandas
    jieba
    lightgbm
    warnings
    missingno
    seaborn
    datetime
    sklearn
    ```
    
-   **方法概述**： 

本教程包括以下内容：数据分析、特征提取、特征筛选、模型训练、参数调优 ![流程图.png](https://work-storage.datafountain.cn/ceph-s3/api/notebook_assets/files/%E6%88%AA%E5%B1%8F2021-05-23%20%E4%B8%8A%E5%8D%889.49.33-872377.png)
    

## 1.数据分析

（1）已标注数据：共7000篇文档，类别包含7类，分别为：财经、房产、家居、教育、科技、时尚、时政，每一类包含1000篇文档。 （2）未标注数据：共33000篇文档。 （3）分类分级测试数据：共20000篇文档，包含10个类别:财经、房产、家居、教育、科技、时尚、时政、游戏、娱乐、体育

已标注的数据共7个类别，每个类别1000篇，而测试数据包含10个类别。首先得先找出另外的3个类别的数据，然后再进行数据的处理。解决的思路有：

1.采用在信息抽取领域称为“远程监督”的方法，具体见：[https://zhuanlan.zhihu.com/p/273756508](https://zhuanlan.zhihu.com/p/273756508) 能取得不错的召回率

2.采用无监督的算法进行预料的预训练，然后进行无监督文本抽取，最后进行微调。具体参考：[https://zhuanlan.zhihu.com/p/350937332](https://zhuanlan.zhihu.com/p/350937332)

将抽取出来的数据进行随机选取，每个类别共1000条，添加到训练集中，于是我们就有了10个类别的数据。

## 2.数据读取与预处理

主要进行分词和停用词过滤。分词是对新闻文本采用jieba分词，然后对分词后的结果进行停用词的过滤，最后将分词后的结果合起来组成新的句子。

## 3\. 文本特征提取

使用sklearn计算训练集的TF-IDF，并将训练集和测试集分别转换为TF-IDF权重矩阵，作为模型的输入。

至此，我们已经通过lgb模型训练与预测得出了test\_data.csv新闻文本预测的结果。

## 5\. 最优化参数搜索

5.1 利用lgb.cv进行交叉验证，获取到最佳迭代次数

5.2 抽取部分训练集为验证集，使用验证集对lgb训练结果进行验证，选取最佳迭代次数进行进行测试集的预测。测试集的数量可以不断尝试，但是要保证每个类别的数量均匀。验证集与训练集进行一样的处理。

## 6.优化思路

（1）LGB参数调优： a.提高准确率：

1.learning\_rate:学习率. 默认值：0.1 调参策略：最开始可以设置得大一些，如0.1。调整完其他参数之后最后再将此参数调小。 取值范围:0.01~0.3.

2.max\_depth:树模型深度 默认值：-1 调整策略:无 取值范围：3-8（不超过10）

3.num\_leaves:叶子节点数，数模型复杂度。 默认值：31 调整策略：可以设置为2的n次幂。但要大于分类的类别数 取值范围：classes<num\_leaves <2^{max\_depth}

b.降低过拟合

1.max\_bin:工具箱数,工具箱的最大数特征值决定了容量 工具箱的最小数特征值可能会降低训练的准确性, 但是可能会增加一些一般的影响（处理过度学习）

2.min\_data\_in\_leaf:一个叶子上数据的最小数量. 可以用来处理过拟合. 默认值：20 调参策略：搜索，尽量不要太大。

3.feature\_fraction：每次迭代中随机选择特征的比例。默认值：1.0 调参策略：0.5-0.9之间调节。 可以用来加速训练 可以用来处理过拟合

4.bagging\_fraction：不进行重采样的情况下随机选择部分数据 默认值：1.0 调参策略：0.5-0.9之间调节。 可以用来加速训练 可以用来处理过拟合

5.bagging\_freq：bagging的次数。0表示禁用bagging，非零值表示执行k次bagging 默认值：0 调参策略：3-5

6.lambda\_l1:L1正则 lambda\_l2:L2正则

7.min\_split\_gain：执行切分的最小增益 默认值：0.1

（2）优化补充类别的方法

## 8\. 总结

当参加数据科学的比赛时，不妨先试着用常见的模型进行处理，然后挑选最适合的模型进行调优。前期大量方法模型的尝试是很有必要的，一方面能令我们加深对题目的理解，另一方面通过各种模型之间的对比，观察各个优异模型结果的共性，能方便我们针对性的进行优化，然后也能取得较为满意的分数。因为我不是专业的，不了解很多复杂的模型、步骤，但通过简单模型的尝试组合，然后进行模型调整，强化性的加深对模型参数的理解，学会如何用调整参数的方法处理训练中遇到的情况，将理论用于实践；或者多模型融合，进行投票，以取得更为精确的结果。使用多种算法，再对算法进行具体的调整，这也不失为一条学习与成长的路子。
